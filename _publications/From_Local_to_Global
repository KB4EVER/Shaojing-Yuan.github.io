---
title: "From Local to Global: Two-step Image Annotation via Multi-grained Visual-Semantic Embedding and Attention Mechanism (In Review)"
collection: publications
excerpt: 'Automatic image annotation (AIA) aims to describe an image using a limited number of tags, which accurately represent the semantic information about the image. AIA is of great importance to search, browse and manage large-scale image collections. However, existing AIA methods mainly concentrate on learning the correlations between images and collection of tags while ignoring the relationships between image patches and tags. This paper proposes a “From Local to Global” strategy based two-step AIA method, which annotates the whole image at the global level by exploring the relatedness between image patches and tags at the local level. In step 1, candidate tags are chosen from a multi-grained embedding space, which effectively fuses shared information between visual and language modalities. Particularly, this embedding space is constructed by learning a projection matrix for each data modality based on the proposed Multi-Grained Visual-Semantic Embedding (MGVSE) framework integrated with the Fine-Grained Correspondences Inferring (FGCI) algorithm. In step 2, final annotations are gained by ranking all candidate tags according to confidence scores calculated by the proposed Attention Mechanism based Dual Embedding Space model (AMDES). Specifically, AMDES fully utilizes the complementary information between two modalities. Experimental results clearly prove the effectiveness of our proposed solution.'
date: 
venue: 
paperurl: 
citation: 
---
Automatic image annotation (AIA) aims to describe an image using a limited number of tags, which accurately represent the semantic information about the image. AIA is of great importance to search, browse and manage large-scale image collections. However, existing AIA methods mainly concentrate on learning the correlations between images and collection of tags while ignoring the relationships between image patches and tags. This paper proposes a “From Local to Global” strategy based two-step AIA method, which annotates the whole image at the global level by exploring the relatedness between image patches and tags at the local level. In step 1, candidate tags are chosen from a multi-grained embedding space, which effectively fuses shared information between visual and language modalities. Particularly, this embedding space is constructed by learning a projection matrix for each data modality based on the proposed Multi-Grained Visual-Semantic Embedding (MGVSE) framework integrated with the Fine-Grained Correspondences Inferring (FGCI) algorithm. In step 2, final annotations are gained by ranking all candidate tags according to confidence scores calculated by the proposed Attention Mechanism based Dual Embedding Space model (AMDES). Specifically, AMDES fully utilizes the complementary information between two modalities. Experimental results clearly prove the effectiveness of our proposed solution
